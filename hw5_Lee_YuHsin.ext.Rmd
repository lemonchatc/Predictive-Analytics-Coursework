---
title: "Exponential Smoothing Models"
author: "Kathy Yu Hsin Lee"
date: "5/8/2021"
output: html_document
---
**Load packages and data set**
```{r}
library(dplyr)
library(ggplot2)
library(gridExtra)
library(fpp2)

setwd("/Users/KathyLee/UCI MSBA/Course Material/05 Spring Quarter/BANA288 Predictive Analytics/Homework")
data <-  read.csv("hw5_bike_share_day.csv")
```

<br><br>

**1.	Create time series object from the bike sharing data with frequency 7, call the resulting series “cntts”.  Fit the simple exponential smoothing (ses) model to the bike sharing data with alpha = 0.25 and initial value equal to the first value of count (cntts) in the series.  Compare the result of this model to the ses model with both parameters optimized.  Which is a better fit?  Why?**
```{r}
# Create a time series object, "cntts"
cntts <- ts(data$cnt, start = 1, frequency = 7)

# Fit the simple exponential smoothing (ses) model with alpha = 0.25
mod.ses1 <- ses(cntts, alpha = 0.25, initial = "simple")
summary(mod.ses1)

# Fit the ses model with both parameters optimized
mod.ses2 <- ses(cntts)
summary(mod.ses2)

```

- According to the model results, overall the ses model with both parameters optimized fits better. Its RMSE value is smaller. 

<br><br>

**2.	Fit Holt’s model with the bike sharing data series, cntts. Compare the results of this model with the best model from question 1. Which is a better fit? Why? **
```{r}
# Holt's model
mod.hlt <- holt(cntts)
summary(mod.hlt)

```

- Compared with the previous model (mod.ses2), mod.hlt has slightly larger RMSE value. Therefore, mod.ses2 is a better fit.

<br><br>

**3.	Fit Holt-Winters’ seasonal method using the additive, multiplicative, and the damped multiplicative methods. Which of these models is preferred? How did this model compare to the models from questions 1 and 2?  Are the results surprising?  Explain.**
```{r}
# Holt-Winters' seasonal method using the addictive method
mod.hltw1 <- hw(cntts, seasonal = "additive")

#                   ME     RMSE      MAE       MPE     MAPE      MASE      ACF1
# Training set -7.00276 953.1229 673.9503 -48.79808 62.94175 0.7219436 0.1939853


# Holt-Winters' seasonal method using the multiplicative method
mod.hltw2 <- hw(cntts, seasonal = "multiplicative")

#                    ME     RMSE     MAE       MPE     MAPE      MASE      ACF1
# Training set -32.03015 957.2871 676.216 -49.11687 62.66111 0.7243706 0.2225966


# Holt-Winters' seasonal method using the damped method
mod.hltw3 <- hw(cntts, damped = TRUE, seasonal = "multiplicative")

#                    ME     RMSE     MAE       MPE     MAPE     MASE      ACF1
# Training set 0.8785052 944.5366 671.012 -47.27041 61.54923 0.718796 0.1991828


```

- Holt-Winters' seasonal method using the damped method (mod.hltw3) is preferred within these three models. Compared to models from Q1, mod.hltw3 still fits better. It is not surprised because Holt-Winters' seasonal method with a damped trend and multiplicative seasonality often provides accurate and robust forecasts for seasonal data.

<br><br>

**4.	Create forecasts for the preferred model from questions 1-3 for the next 4 weeks. Display the values of the forecasts to the console and plot the forecasts on a time-oriented graph.**
```{r}
mod.hltw3.1 <- hw(cntts, damped = TRUE, seasonal = "multiplicative", h = 28)
summary(mod.hltw3.1)

autoplot(cntts) +
  autolayer(mod.hltw3.1, series = "Holt-Winters' Method", PI = FALSE) + 
  ggtitle("Forecast from Holt-Winters' method using the damped method") + 
  xlab("Week") + 
  ylab("Count of Bike Shared") + 
  guides(colour = guide_legend(title = "Forecast"))

```

<br><br>

**5.	Load the Johnson and Johnson data set (JohnsonJohnson).  Describe this data.  What is the data range?  How many observations?  What is periodicity of this data set?  Run the “AAA” ETS model on the earnings for Johnson and Johnson. Report the coefficients and the fit of the AAA ETS model. Plot the three model components.**
```{r}
# Load the Johnson and Johnson data set
#fix(JohnsonJohnson)
#?JohnsonJohnson

# Run the "AAA" ETS model on the earnings for Johnson and Johnson
mod.ets <- ets(JohnsonJohnson , model = "AAA")
summary(mod.ets)

# Report the coefficients and the fit
coef(mod.ets)
accuracy(mod.ets)
fitted(mod.ets)

autoplot(mod.ets)

```

- Johnson and Johnson data set contains quarterly earnings per Johnson & Johnson share. The data range from 1960 to 1980. There are total 80 observations. The periodicity of this data set is quarter. 

<br><br>

**6. Compute the best ETS model on the Johnson and Johnson data. Select the model that is preferred from the models fit questions 5 and 6. Explain why the chosen model is preferred.**
```{r}
# Compute the best ETS model
mod.ets2 <- ets(JohnsonJohnson)
summary(mod.ets2)

```

- The AAA model from Q5 is preferred because it has smaller value of RMSE. 

<br><br>

**7.	How is the preferred model selected by the ETS command when the modeler does not specify a certain type of ETS model?  Explain in a few sentences.**

- The ETS command uses the AICc value to rank and select an appropriate model. The model with lowest AICc value will be selected. 

<br><br>

**8.	Compute the best ETS model on the monthly debit card use in Iceland (data set “debitcards”).  What model was chosen?  What are the associated parameters?  Display the model components (chart). Make forecasts with 80% confidence bands for the next two years using the chosen model. Graph the data and the forecasts.**
```{r}
# Load the monthly debit card use in Iceland data set from fpp2
#fix(debitcards)

# Compute the best ETS model
mod.ets3 <- ets(debitcards)
summary(mod.ets3)

# Display the model components
coef(mod.ets3)

# Make forecasts with 80% confidence bands for the next two years
for.ets3 <- forecast(mod.ets3, h = 24, level = 80)

autoplot(for.ets3) +
  ggtitle("Retail Debit Card Usage with Forecasts") + 
  ylab("Millions ISK") +
  xlab("Year")

```

- The MAM model was chosen. alpha = 0.3831, beta  = 1e-04, gamma = 5e-04


<br><br>

**9.	Compute the best ETS model on the Google closing price data (data set “goog”). What model was chosen? What are the associated parameters?  Display the model components. Make forecasts for the next 30 days using the chosen model. Graph the data and the forecasts.** 
```{r}
# Load the Google closing price data from fpp2
#fix(goog)

# Compute the best ETS model
mod.ets4 <- ets(goog)
summary(mod.ets4)

# Display the model components
coef(mod.ets4)

# Forecast
for.ets4 <- forecast(mod.ets4, h = 30)

autoplot(for.ets4) +
  ggtitle("Daily Closing Stock Prices of Google with Forecasts") + 
  ylab("Price") +
  xlab("Day")

```

- The MNN model was chosen. alpha = 0.9999, l = 392.7798 

<br><br>

**10.	Compare the results of question 9 with a “best” ARIMA model on data set “goog”. Which technique works better?  What is the chosen model?  Why did you choose that model? What are the model’s parameters?  What is the model error? See Chapter 8 in Hyndman for information on interpreting the results.**
```{r}
# Run the automated ARIMA model selection
mod.arima <- auto.arima(goog)
summary(mod.arima)

# Compare model from Q9 with ARIMA model
fets <- function(x, h) { forecast(ets(x), h = h)}
farima <- function(x, h) { forecast(auto.arima(x), h = h)}

# Compute CV errors for ETS
ets <- tsCV(goog, fets, h = 30)
# Compute CV errors for ARIMA
arim <- tsCV(goog, farima, h = 30)

# Find RMSE of each model class
(mean(ets^2, na.rm = TRUE))^0.5
(mean(arim^2, na.rm = TRUE))^0.5

# Parameters of ETS model
coef(mod.ets4)

```

- The "best" ARIMA model computed by auto.arima command is ARIMA(0,1,0) with drift. The RMSE value is 8.724121.
- After computing CV errors for both ETS MNN model from Q9 and ARIMA model from Q10, the ETS MNN model has a smaller value of RMSE (31.63468). Therefore, I would choose the MNN model. 

